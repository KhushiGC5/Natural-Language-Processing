{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXM2LndnmU_4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, RNN, SimpleRNN, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, AdamW, SGD\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "train_data = pd.read_csv('train_split.csv')\n",
        "test_data = pd.read_csv('test_split.csv')\n",
        "\n",
        "# Preprocessing\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_data['text'])\n",
        "\n",
        "# Convert text to sequences\n",
        "X_train = tokenizer.texts_to_sequences(train_data['text'])\n",
        "X_test = tokenizer.texts_to_sequences(test_data['text'])\n",
        "\n",
        "# Padding sequences\n",
        "max_len = 128\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)\n",
        "\n",
        "# Label encoding the target variables (for multi-label classification)\n",
        "y_train = train_data[['Joy', 'Fear', 'Anger', 'Sadness', 'Surprise']].values\n",
        "y_test = test_data[['Joy', 'Fear', 'Anger', 'Sadness', 'Surprise']].values\n"
      ],
      "metadata": {
        "id": "GirfDeIomW73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Create Word2Vec embeddings\n",
        "word2vec = Word2Vec(sentences=[row.split() for row in train_data['text']], vector_size=100, window=5, min_count=1, workers=4)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Create an embedding matrix\n",
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in word2vec.wv:\n",
        "        embedding_matrix[i] = word2vec.wv[word]\n",
        "\n",
        "# Define embedding layer\n",
        "embedding_layer = Embedding(input_dim=vocab_size, output_dim=100, weights=[embedding_matrix], input_length=max_len, trainable=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n581oDm4m6jh",
        "outputId": "f7347d25-5108-4e0f-a279-a3ddbc9101e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Train Word2Vec model on the dataset (if not pretrained)\n",
        "sentences = [sentence.split() for sentence in train_data['text']]\n",
        "word2vec = Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Save the Word2Vec model\n",
        "word2vec.save(\"word2vec_model.model\")\n"
      ],
      "metadata": {
        "id": "3F34DB9JonwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1  # Get the vocabulary size\n",
        "\n",
        "# Initialize the embedding matrix with zeros\n",
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "\n",
        "# Populate the embedding matrix with Word2Vec vectors\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in word2vec.wv:\n",
        "        embedding_matrix[i] = word2vec.wv[word]\n"
      ],
      "metadata": {
        "id": "LfINX_EaoqCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save embedding matrix as a .npy file\n",
        "np.save('embedding_matrix.npy', embedding_matrix)\n"
      ],
      "metadata": {
        "id": "WZfqs5Gvot4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the embedding matrix from .npy file\n",
        "embedding_matrix = np.load('embedding_matrix.npy')\n",
        "\n",
        "# Create an Embedding layer in Keras using the loaded embedding matrix\n",
        "embedding_layer = Embedding(input_dim=vocab_size,\n",
        "                            output_dim=100,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=max_len,\n",
        "                            trainable=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwUuuvEkoy3F",
        "outputId": "48075e5e-c877-4b71-d4e7-58819b3aa24b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_ffnn():\n",
        "    model = Sequential()\n",
        "    model.add(embedding_layer)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(5, activation='sigmoid'))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "x0HuH8V5m8cH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_rnn():\n",
        "    model = Sequential()\n",
        "    model.add(embedding_layer)\n",
        "    model.add(SimpleRNN(64, return_sequences=False))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(5, activation='sigmoid'))\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "WhJg7uofnBNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lstm():\n",
        "    model = Sequential()\n",
        "    model.add(embedding_layer)\n",
        "    model.add(LSTM(64, return_sequences=False))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(5, activation='sigmoid'))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "KcPPF2JonDoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'FFNN': create_ffnn(),\n",
        "    'RNN': create_rnn(),\n",
        "    'LSTM': create_lstm()\n",
        "}\n",
        "\n",
        "best_f1 = 0\n",
        "best_model_name = None\n",
        "best_model = None\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
        "\n",
        "    # Predict and calculate F1-macro score\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred = np.round(y_pred)\n",
        "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "    if f1_macro > best_f1:\n",
        "        best_f1 = f1_macro\n",
        "        best_model_name = name\n",
        "        best_model = model\n",
        "\n",
        "# Save the best model\n",
        "best_model.save('best_model.h5')\n",
        "print(f\"Best model is {best_model_name} with F1-macro score: {best_f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a4XuRDxnF-K",
        "outputId": "6e57123a-c107-4c8e-bf4e-6e6d80c6f133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3424 - loss: 0.6390 - val_accuracy: 0.5437 - val_loss: 0.5802\n",
            "Epoch 2/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4799 - loss: 0.5977 - val_accuracy: 0.5688 - val_loss: 0.5724\n",
            "Epoch 3/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4865 - loss: 0.5945 - val_accuracy: 0.5656 - val_loss: 0.5681\n",
            "Epoch 4/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5109 - loss: 0.5784 - val_accuracy: 0.5656 - val_loss: 0.5678\n",
            "Epoch 5/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5225 - loss: 0.5793 - val_accuracy: 0.5656 - val_loss: 0.5654\n",
            "Epoch 6/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5094 - loss: 0.5801 - val_accuracy: 0.5656 - val_loss: 0.5685\n",
            "Epoch 7/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5409 - loss: 0.5790 - val_accuracy: 0.5656 - val_loss: 0.5725\n",
            "Epoch 8/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5303 - loss: 0.5821 - val_accuracy: 0.5625 - val_loss: 0.5656\n",
            "Epoch 9/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5320 - loss: 0.5679 - val_accuracy: 0.5656 - val_loss: 0.5661\n",
            "Epoch 10/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5168 - loss: 0.5757 - val_accuracy: 0.5688 - val_loss: 0.5604\n",
            "Epoch 11/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5090 - loss: 0.5754 - val_accuracy: 0.5656 - val_loss: 0.5617\n",
            "Epoch 12/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5274 - loss: 0.5689 - val_accuracy: 0.5688 - val_loss: 0.5642\n",
            "Epoch 13/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5543 - loss: 0.5688 - val_accuracy: 0.5625 - val_loss: 0.5610\n",
            "Epoch 14/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5514 - loss: 0.5662 - val_accuracy: 0.5656 - val_loss: 0.5610\n",
            "Epoch 15/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5509 - loss: 0.5617 - val_accuracy: 0.5656 - val_loss: 0.5617\n",
            "Epoch 16/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5210 - loss: 0.5596 - val_accuracy: 0.5656 - val_loss: 0.5641\n",
            "Epoch 17/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5511 - loss: 0.5614 - val_accuracy: 0.5594 - val_loss: 0.5611\n",
            "Epoch 18/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5373 - loss: 0.5570 - val_accuracy: 0.5594 - val_loss: 0.5626\n",
            "Epoch 19/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5326 - loss: 0.5710 - val_accuracy: 0.5594 - val_loss: 0.5599\n",
            "Epoch 20/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5535 - loss: 0.5588 - val_accuracy: 0.5625 - val_loss: 0.5651\n",
            "Epoch 21/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5345 - loss: 0.5575 - val_accuracy: 0.5562 - val_loss: 0.5666\n",
            "Epoch 22/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5318 - loss: 0.5572 - val_accuracy: 0.5625 - val_loss: 0.5609\n",
            "Epoch 23/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5319 - loss: 0.5610 - val_accuracy: 0.5625 - val_loss: 0.5621\n",
            "Epoch 24/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5540 - loss: 0.5456 - val_accuracy: 0.5500 - val_loss: 0.5668\n",
            "Epoch 25/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5407 - loss: 0.5508 - val_accuracy: 0.5562 - val_loss: 0.5650\n",
            "Epoch 26/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5375 - loss: 0.5468 - val_accuracy: 0.5531 - val_loss: 0.5667\n",
            "Epoch 27/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5209 - loss: 0.5496 - val_accuracy: 0.5625 - val_loss: 0.5651\n",
            "Epoch 28/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5442 - loss: 0.5417 - val_accuracy: 0.5594 - val_loss: 0.5655\n",
            "Epoch 29/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5407 - loss: 0.5472 - val_accuracy: 0.5594 - val_loss: 0.5640\n",
            "Epoch 30/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5464 - loss: 0.5420 - val_accuracy: 0.5594 - val_loss: 0.5641\n",
            "Epoch 31/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5859 - loss: 0.5496 - val_accuracy: 0.5500 - val_loss: 0.5688\n",
            "Epoch 32/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5646 - loss: 0.5380 - val_accuracy: 0.5562 - val_loss: 0.5662\n",
            "Epoch 33/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5431 - loss: 0.5435 - val_accuracy: 0.5625 - val_loss: 0.5635\n",
            "Epoch 34/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5712 - loss: 0.5423 - val_accuracy: 0.5500 - val_loss: 0.5642\n",
            "Epoch 35/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5316 - loss: 0.5426 - val_accuracy: 0.5625 - val_loss: 0.5632\n",
            "Epoch 36/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5124 - loss: 0.5458 - val_accuracy: 0.5500 - val_loss: 0.5669\n",
            "Epoch 37/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5512 - loss: 0.5326 - val_accuracy: 0.5562 - val_loss: 0.5651\n",
            "Epoch 38/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5674 - loss: 0.5377 - val_accuracy: 0.5562 - val_loss: 0.5651\n",
            "Epoch 39/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5656 - loss: 0.5315 - val_accuracy: 0.5437 - val_loss: 0.5661\n",
            "Epoch 40/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5370 - loss: 0.5400 - val_accuracy: 0.5406 - val_loss: 0.5648\n",
            "Epoch 41/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5486 - loss: 0.5344 - val_accuracy: 0.5437 - val_loss: 0.5641\n",
            "Epoch 42/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5329 - loss: 0.5362 - val_accuracy: 0.5469 - val_loss: 0.5690\n",
            "Epoch 43/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5657 - loss: 0.5319 - val_accuracy: 0.5500 - val_loss: 0.5633\n",
            "Epoch 44/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5662 - loss: 0.5394 - val_accuracy: 0.5500 - val_loss: 0.5637\n",
            "Epoch 45/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5469 - loss: 0.5295 - val_accuracy: 0.5531 - val_loss: 0.5660\n",
            "Epoch 46/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5553 - loss: 0.5272 - val_accuracy: 0.5500 - val_loss: 0.5636\n",
            "Epoch 47/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5569 - loss: 0.5307 - val_accuracy: 0.5406 - val_loss: 0.5646\n",
            "Epoch 48/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5520 - loss: 0.5289 - val_accuracy: 0.5469 - val_loss: 0.5650\n",
            "Epoch 49/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5611 - loss: 0.5263 - val_accuracy: 0.5469 - val_loss: 0.5633\n",
            "Epoch 50/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5527 - loss: 0.5283 - val_accuracy: 0.5469 - val_loss: 0.5667\n",
            "Epoch 51/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5667 - loss: 0.5195 - val_accuracy: 0.5500 - val_loss: 0.5674\n",
            "Epoch 52/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5576 - loss: 0.5344 - val_accuracy: 0.5437 - val_loss: 0.5733\n",
            "Epoch 53/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5444 - loss: 0.5319 - val_accuracy: 0.5531 - val_loss: 0.5681\n",
            "Epoch 54/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5614 - loss: 0.5233 - val_accuracy: 0.5437 - val_loss: 0.5691\n",
            "Epoch 55/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5766 - loss: 0.5294 - val_accuracy: 0.5469 - val_loss: 0.5636\n",
            "Epoch 56/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5495 - loss: 0.5334 - val_accuracy: 0.5437 - val_loss: 0.5691\n",
            "Epoch 57/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5741 - loss: 0.5221 - val_accuracy: 0.5312 - val_loss: 0.5669\n",
            "Epoch 58/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5427 - loss: 0.5271 - val_accuracy: 0.5406 - val_loss: 0.5690\n",
            "Epoch 59/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5602 - loss: 0.5242 - val_accuracy: 0.5562 - val_loss: 0.5676\n",
            "Epoch 60/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5694 - loss: 0.5239 - val_accuracy: 0.5625 - val_loss: 0.5688\n",
            "Epoch 61/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5649 - loss: 0.5253 - val_accuracy: 0.5437 - val_loss: 0.5675\n",
            "Epoch 62/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5501 - loss: 0.5220 - val_accuracy: 0.5375 - val_loss: 0.5714\n",
            "Epoch 63/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5685 - loss: 0.5274 - val_accuracy: 0.5406 - val_loss: 0.5669\n",
            "Epoch 64/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5506 - loss: 0.5212 - val_accuracy: 0.5500 - val_loss: 0.5728\n",
            "Epoch 65/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5537 - loss: 0.5235 - val_accuracy: 0.5437 - val_loss: 0.5692\n",
            "Epoch 66/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5509 - loss: 0.5257 - val_accuracy: 0.5375 - val_loss: 0.5742\n",
            "Epoch 67/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5697 - loss: 0.5269 - val_accuracy: 0.5469 - val_loss: 0.5713\n",
            "Epoch 68/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5741 - loss: 0.5092 - val_accuracy: 0.5406 - val_loss: 0.5690\n",
            "Epoch 69/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5739 - loss: 0.5173 - val_accuracy: 0.5437 - val_loss: 0.5723\n",
            "Epoch 70/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5612 - loss: 0.5229 - val_accuracy: 0.5562 - val_loss: 0.5723\n",
            "Epoch 71/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5497 - loss: 0.5148 - val_accuracy: 0.5469 - val_loss: 0.5708\n",
            "Epoch 72/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5521 - loss: 0.5238 - val_accuracy: 0.5437 - val_loss: 0.5738\n",
            "Epoch 73/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5591 - loss: 0.5214 - val_accuracy: 0.5437 - val_loss: 0.5719\n",
            "Epoch 74/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5619 - loss: 0.5135 - val_accuracy: 0.5437 - val_loss: 0.5762\n",
            "Epoch 75/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5352 - loss: 0.5203 - val_accuracy: 0.5375 - val_loss: 0.5729\n",
            "Epoch 76/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5588 - loss: 0.5154 - val_accuracy: 0.5437 - val_loss: 0.5731\n",
            "Epoch 77/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5366 - loss: 0.5283 - val_accuracy: 0.5406 - val_loss: 0.5740\n",
            "Epoch 78/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5824 - loss: 0.5092 - val_accuracy: 0.5437 - val_loss: 0.5786\n",
            "Epoch 79/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5547 - loss: 0.5314 - val_accuracy: 0.5531 - val_loss: 0.5715\n",
            "Epoch 80/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5393 - loss: 0.5109 - val_accuracy: 0.5500 - val_loss: 0.5810\n",
            "Epoch 81/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5571 - loss: 0.5196 - val_accuracy: 0.5469 - val_loss: 0.5728\n",
            "Epoch 82/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5701 - loss: 0.5115 - val_accuracy: 0.5437 - val_loss: 0.5760\n",
            "Epoch 83/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5447 - loss: 0.5219 - val_accuracy: 0.5344 - val_loss: 0.5825\n",
            "Epoch 84/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5676 - loss: 0.5002 - val_accuracy: 0.5281 - val_loss: 0.5792\n",
            "Epoch 85/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5711 - loss: 0.5149 - val_accuracy: 0.5437 - val_loss: 0.5777\n",
            "Epoch 86/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5442 - loss: 0.5077 - val_accuracy: 0.5281 - val_loss: 0.5810\n",
            "Epoch 87/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5697 - loss: 0.5155 - val_accuracy: 0.5406 - val_loss: 0.5775\n",
            "Epoch 88/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5537 - loss: 0.5156 - val_accuracy: 0.5375 - val_loss: 0.5816\n",
            "Epoch 89/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5692 - loss: 0.5112 - val_accuracy: 0.5344 - val_loss: 0.5823\n",
            "Epoch 90/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5620 - loss: 0.5089 - val_accuracy: 0.5406 - val_loss: 0.5848\n",
            "Epoch 91/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5651 - loss: 0.5172 - val_accuracy: 0.5469 - val_loss: 0.5808\n",
            "Epoch 92/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5555 - loss: 0.5140 - val_accuracy: 0.5344 - val_loss: 0.5841\n",
            "Epoch 93/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5369 - loss: 0.5139 - val_accuracy: 0.5375 - val_loss: 0.5827\n",
            "Epoch 94/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5655 - loss: 0.5062 - val_accuracy: 0.5437 - val_loss: 0.5819\n",
            "Epoch 95/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5625 - loss: 0.5211 - val_accuracy: 0.5406 - val_loss: 0.5800\n",
            "Epoch 96/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5686 - loss: 0.5104 - val_accuracy: 0.5469 - val_loss: 0.5823\n",
            "Epoch 97/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5465 - loss: 0.5130 - val_accuracy: 0.5344 - val_loss: 0.5819\n",
            "Epoch 98/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5679 - loss: 0.5094 - val_accuracy: 0.5500 - val_loss: 0.5804\n",
            "Epoch 99/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5492 - loss: 0.5061 - val_accuracy: 0.5500 - val_loss: 0.5799\n",
            "Epoch 100/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5620 - loss: 0.5128 - val_accuracy: 0.5469 - val_loss: 0.5809\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Epoch 1/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.3374 - loss: 0.6647 - val_accuracy: 0.5594 - val_loss: 0.5613\n",
            "Epoch 2/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4525 - loss: 0.6054 - val_accuracy: 0.5688 - val_loss: 0.5624\n",
            "Epoch 3/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4502 - loss: 0.6002 - val_accuracy: 0.5688 - val_loss: 0.5622\n",
            "Epoch 4/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4710 - loss: 0.5889 - val_accuracy: 0.5688 - val_loss: 0.5626\n",
            "Epoch 5/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4595 - loss: 0.5883 - val_accuracy: 0.5688 - val_loss: 0.5578\n",
            "Epoch 6/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5189 - loss: 0.5799 - val_accuracy: 0.5688 - val_loss: 0.5641\n",
            "Epoch 7/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5283 - loss: 0.5797 - val_accuracy: 0.5688 - val_loss: 0.5593\n",
            "Epoch 8/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5251 - loss: 0.5756 - val_accuracy: 0.5688 - val_loss: 0.5605\n",
            "Epoch 9/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5174 - loss: 0.5791 - val_accuracy: 0.5688 - val_loss: 0.5586\n",
            "Epoch 10/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5192 - loss: 0.5851 - val_accuracy: 0.5688 - val_loss: 0.5587\n",
            "Epoch 11/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5203 - loss: 0.5810 - val_accuracy: 0.5688 - val_loss: 0.5578\n",
            "Epoch 12/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5348 - loss: 0.5787 - val_accuracy: 0.5688 - val_loss: 0.5582\n",
            "Epoch 13/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5217 - loss: 0.5707 - val_accuracy: 0.5688 - val_loss: 0.5615\n",
            "Epoch 14/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5042 - loss: 0.5807 - val_accuracy: 0.5688 - val_loss: 0.5564\n",
            "Epoch 15/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5551 - loss: 0.5844 - val_accuracy: 0.5688 - val_loss: 0.5563\n",
            "Epoch 16/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5424 - loss: 0.5714 - val_accuracy: 0.5688 - val_loss: 0.5610\n",
            "Epoch 17/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5303 - loss: 0.5785 - val_accuracy: 0.5688 - val_loss: 0.5548\n",
            "Epoch 18/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5236 - loss: 0.5745 - val_accuracy: 0.5688 - val_loss: 0.5566\n",
            "Epoch 19/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5320 - loss: 0.5710 - val_accuracy: 0.5719 - val_loss: 0.5582\n",
            "Epoch 20/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5207 - loss: 0.5653 - val_accuracy: 0.5719 - val_loss: 0.5561\n",
            "Epoch 21/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5206 - loss: 0.5696 - val_accuracy: 0.5688 - val_loss: 0.5562\n",
            "Epoch 22/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5303 - loss: 0.5659 - val_accuracy: 0.5719 - val_loss: 0.5591\n",
            "Epoch 23/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5541 - loss: 0.5660 - val_accuracy: 0.5562 - val_loss: 0.5600\n",
            "Epoch 24/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5196 - loss: 0.5651 - val_accuracy: 0.5437 - val_loss: 0.5574\n",
            "Epoch 25/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5348 - loss: 0.5693 - val_accuracy: 0.5688 - val_loss: 0.5566\n",
            "Epoch 26/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5152 - loss: 0.5783 - val_accuracy: 0.5656 - val_loss: 0.5560\n",
            "Epoch 27/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5083 - loss: 0.5682 - val_accuracy: 0.5688 - val_loss: 0.5555\n",
            "Epoch 28/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5258 - loss: 0.5657 - val_accuracy: 0.5656 - val_loss: 0.5574\n",
            "Epoch 29/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5491 - loss: 0.5632 - val_accuracy: 0.5719 - val_loss: 0.5549\n",
            "Epoch 30/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5428 - loss: 0.5637 - val_accuracy: 0.5656 - val_loss: 0.5563\n",
            "Epoch 31/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5298 - loss: 0.5721 - val_accuracy: 0.5562 - val_loss: 0.5569\n",
            "Epoch 32/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5425 - loss: 0.5695 - val_accuracy: 0.5688 - val_loss: 0.5574\n",
            "Epoch 33/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5387 - loss: 0.5660 - val_accuracy: 0.5500 - val_loss: 0.5551\n",
            "Epoch 34/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5101 - loss: 0.5734 - val_accuracy: 0.5688 - val_loss: 0.5555\n",
            "Epoch 35/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4979 - loss: 0.5742 - val_accuracy: 0.5688 - val_loss: 0.5544\n",
            "Epoch 36/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5272 - loss: 0.5617 - val_accuracy: 0.5656 - val_loss: 0.5561\n",
            "Epoch 37/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5323 - loss: 0.5729 - val_accuracy: 0.5562 - val_loss: 0.5567\n",
            "Epoch 38/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5083 - loss: 0.5613 - val_accuracy: 0.5688 - val_loss: 0.5538\n",
            "Epoch 39/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5240 - loss: 0.5661 - val_accuracy: 0.5688 - val_loss: 0.5577\n",
            "Epoch 40/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5271 - loss: 0.5710 - val_accuracy: 0.5688 - val_loss: 0.5578\n",
            "Epoch 41/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5460 - loss: 0.5667 - val_accuracy: 0.5688 - val_loss: 0.5539\n",
            "Epoch 42/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5343 - loss: 0.5671 - val_accuracy: 0.5719 - val_loss: 0.5558\n",
            "Epoch 43/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5113 - loss: 0.5650 - val_accuracy: 0.5562 - val_loss: 0.5540\n",
            "Epoch 44/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5041 - loss: 0.5702 - val_accuracy: 0.5656 - val_loss: 0.5560\n",
            "Epoch 45/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5333 - loss: 0.5552 - val_accuracy: 0.5656 - val_loss: 0.5579\n",
            "Epoch 46/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5385 - loss: 0.5625 - val_accuracy: 0.5750 - val_loss: 0.5564\n",
            "Epoch 47/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5366 - loss: 0.5522 - val_accuracy: 0.5688 - val_loss: 0.5591\n",
            "Epoch 48/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5148 - loss: 0.5644 - val_accuracy: 0.5656 - val_loss: 0.5561\n",
            "Epoch 49/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5347 - loss: 0.5629 - val_accuracy: 0.5750 - val_loss: 0.5565\n",
            "Epoch 50/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5368 - loss: 0.5582 - val_accuracy: 0.5719 - val_loss: 0.5539\n",
            "Epoch 51/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5113 - loss: 0.5561 - val_accuracy: 0.5750 - val_loss: 0.5540\n",
            "Epoch 52/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5160 - loss: 0.5649 - val_accuracy: 0.5688 - val_loss: 0.5559\n",
            "Epoch 53/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5383 - loss: 0.5624 - val_accuracy: 0.5688 - val_loss: 0.5745\n",
            "Epoch 54/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5001 - loss: 0.5800 - val_accuracy: 0.5750 - val_loss: 0.5563\n",
            "Epoch 55/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5196 - loss: 0.5617 - val_accuracy: 0.5688 - val_loss: 0.5594\n",
            "Epoch 56/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5057 - loss: 0.5598 - val_accuracy: 0.5781 - val_loss: 0.5563\n",
            "Epoch 57/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5080 - loss: 0.5574 - val_accuracy: 0.5531 - val_loss: 0.5630\n",
            "Epoch 58/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5058 - loss: 0.5535 - val_accuracy: 0.5594 - val_loss: 0.5585\n",
            "Epoch 59/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5117 - loss: 0.5629 - val_accuracy: 0.5688 - val_loss: 0.5560\n",
            "Epoch 60/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5337 - loss: 0.5493 - val_accuracy: 0.5656 - val_loss: 0.5566\n",
            "Epoch 61/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5459 - loss: 0.5570 - val_accuracy: 0.5594 - val_loss: 0.5599\n",
            "Epoch 62/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5207 - loss: 0.5600 - val_accuracy: 0.5594 - val_loss: 0.5574\n",
            "Epoch 63/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5300 - loss: 0.5530 - val_accuracy: 0.5688 - val_loss: 0.5602\n",
            "Epoch 64/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5207 - loss: 0.5533 - val_accuracy: 0.5719 - val_loss: 0.5567\n",
            "Epoch 65/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5421 - loss: 0.5526 - val_accuracy: 0.5625 - val_loss: 0.5606\n",
            "Epoch 66/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5285 - loss: 0.5485 - val_accuracy: 0.5719 - val_loss: 0.5600\n",
            "Epoch 67/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5545 - loss: 0.5532 - val_accuracy: 0.5625 - val_loss: 0.5582\n",
            "Epoch 68/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5464 - loss: 0.5514 - val_accuracy: 0.5656 - val_loss: 0.5592\n",
            "Epoch 69/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5281 - loss: 0.5535 - val_accuracy: 0.5437 - val_loss: 0.5583\n",
            "Epoch 70/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5420 - loss: 0.5490 - val_accuracy: 0.5688 - val_loss: 0.5580\n",
            "Epoch 71/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5288 - loss: 0.5491 - val_accuracy: 0.5719 - val_loss: 0.5616\n",
            "Epoch 72/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5219 - loss: 0.5525 - val_accuracy: 0.5625 - val_loss: 0.5637\n",
            "Epoch 73/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5333 - loss: 0.5513 - val_accuracy: 0.5688 - val_loss: 0.5637\n",
            "Epoch 74/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5176 - loss: 0.5488 - val_accuracy: 0.5562 - val_loss: 0.5595\n",
            "Epoch 75/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5191 - loss: 0.5489 - val_accuracy: 0.5625 - val_loss: 0.5667\n",
            "Epoch 76/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5256 - loss: 0.5472 - val_accuracy: 0.5531 - val_loss: 0.5637\n",
            "Epoch 77/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5366 - loss: 0.5520 - val_accuracy: 0.5688 - val_loss: 0.5663\n",
            "Epoch 78/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5323 - loss: 0.5454 - val_accuracy: 0.5531 - val_loss: 0.5617\n",
            "Epoch 79/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5399 - loss: 0.5464 - val_accuracy: 0.5406 - val_loss: 0.5688\n",
            "Epoch 80/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5554 - loss: 0.5354 - val_accuracy: 0.5625 - val_loss: 0.5641\n",
            "Epoch 81/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5498 - loss: 0.5541 - val_accuracy: 0.5562 - val_loss: 0.5711\n",
            "Epoch 82/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5281 - loss: 0.5328 - val_accuracy: 0.5594 - val_loss: 0.5667\n",
            "Epoch 83/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5298 - loss: 0.5457 - val_accuracy: 0.5437 - val_loss: 0.5664\n",
            "Epoch 84/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5054 - loss: 0.5474 - val_accuracy: 0.5594 - val_loss: 0.5631\n",
            "Epoch 85/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5527 - loss: 0.5382 - val_accuracy: 0.5344 - val_loss: 0.5708\n",
            "Epoch 86/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5205 - loss: 0.5407 - val_accuracy: 0.5469 - val_loss: 0.5715\n",
            "Epoch 87/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5305 - loss: 0.5331 - val_accuracy: 0.5562 - val_loss: 0.5676\n",
            "Epoch 88/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5442 - loss: 0.5360 - val_accuracy: 0.5594 - val_loss: 0.5694\n",
            "Epoch 89/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5392 - loss: 0.5406 - val_accuracy: 0.5625 - val_loss: 0.5734\n",
            "Epoch 90/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5800 - loss: 0.5252 - val_accuracy: 0.5469 - val_loss: 0.5723\n",
            "Epoch 91/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5283 - loss: 0.5395 - val_accuracy: 0.5531 - val_loss: 0.5748\n",
            "Epoch 92/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5310 - loss: 0.5327 - val_accuracy: 0.5500 - val_loss: 0.5728\n",
            "Epoch 93/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5765 - loss: 0.5249 - val_accuracy: 0.5500 - val_loss: 0.5722\n",
            "Epoch 94/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5659 - loss: 0.5235 - val_accuracy: 0.5500 - val_loss: 0.5805\n",
            "Epoch 95/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5327 - loss: 0.5297 - val_accuracy: 0.5656 - val_loss: 0.5809\n",
            "Epoch 96/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5822 - loss: 0.5308 - val_accuracy: 0.5469 - val_loss: 0.5828\n",
            "Epoch 97/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5438 - loss: 0.5297 - val_accuracy: 0.5437 - val_loss: 0.5797\n",
            "Epoch 98/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5601 - loss: 0.5213 - val_accuracy: 0.5375 - val_loss: 0.5825\n",
            "Epoch 99/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5819 - loss: 0.5098 - val_accuracy: 0.5188 - val_loss: 0.5856\n",
            "Epoch 100/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5528 - loss: 0.5209 - val_accuracy: 0.5188 - val_loss: 0.5841\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Epoch 1/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 0.5099 - loss: 0.6158 - val_accuracy: 0.5688 - val_loss: 0.5647\n",
            "Epoch 2/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5442 - loss: 0.5814 - val_accuracy: 0.5688 - val_loss: 0.5636\n",
            "Epoch 3/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.5308 - loss: 0.5780 - val_accuracy: 0.5688 - val_loss: 0.5589\n",
            "Epoch 4/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5404 - loss: 0.5761 - val_accuracy: 0.5688 - val_loss: 0.5608\n",
            "Epoch 5/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5268 - loss: 0.5771 - val_accuracy: 0.5688 - val_loss: 0.5595\n",
            "Epoch 6/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.5366 - loss: 0.5767 - val_accuracy: 0.5688 - val_loss: 0.5577\n",
            "Epoch 7/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.5486 - loss: 0.5686 - val_accuracy: 0.5688 - val_loss: 0.5601\n",
            "Epoch 8/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5197 - loss: 0.5729 - val_accuracy: 0.5719 - val_loss: 0.5590\n",
            "Epoch 9/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5545 - loss: 0.5751 - val_accuracy: 0.5656 - val_loss: 0.5572\n",
            "Epoch 10/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.5477 - loss: 0.5681 - val_accuracy: 0.5594 - val_loss: 0.5579\n",
            "Epoch 11/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.5457 - loss: 0.5723 - val_accuracy: 0.5656 - val_loss: 0.5579\n",
            "Epoch 12/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.5432 - loss: 0.5664 - val_accuracy: 0.5688 - val_loss: 0.5552\n",
            "Epoch 13/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5349 - loss: 0.5789 - val_accuracy: 0.5625 - val_loss: 0.5550\n",
            "Epoch 14/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5423 - loss: 0.5707 - val_accuracy: 0.5656 - val_loss: 0.5554\n",
            "Epoch 15/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.5373 - loss: 0.5715 - val_accuracy: 0.5656 - val_loss: 0.5554\n",
            "Epoch 16/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5147 - loss: 0.5719 - val_accuracy: 0.5594 - val_loss: 0.5548\n",
            "Epoch 17/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.5571 - loss: 0.5702 - val_accuracy: 0.5656 - val_loss: 0.5557\n",
            "Epoch 18/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.5222 - loss: 0.5691 - val_accuracy: 0.5594 - val_loss: 0.5538\n",
            "Epoch 19/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5185 - loss: 0.5746 - val_accuracy: 0.5656 - val_loss: 0.5536\n",
            "Epoch 20/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.5389 - loss: 0.5710 - val_accuracy: 0.5656 - val_loss: 0.5580\n",
            "Epoch 21/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.5325 - loss: 0.5670 - val_accuracy: 0.5656 - val_loss: 0.5545\n",
            "Epoch 22/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5326 - loss: 0.5621 - val_accuracy: 0.5656 - val_loss: 0.5544\n",
            "Epoch 23/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.5349 - loss: 0.5718 - val_accuracy: 0.5500 - val_loss: 0.5542\n",
            "Epoch 24/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.5341 - loss: 0.5692 - val_accuracy: 0.5469 - val_loss: 0.5555\n",
            "Epoch 25/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5320 - loss: 0.5710 - val_accuracy: 0.5656 - val_loss: 0.5532\n",
            "Epoch 26/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5401 - loss: 0.5686 - val_accuracy: 0.5500 - val_loss: 0.5543\n",
            "Epoch 27/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.5158 - loss: 0.5728 - val_accuracy: 0.5656 - val_loss: 0.5540\n",
            "Epoch 28/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.5284 - loss: 0.5759 - val_accuracy: 0.5656 - val_loss: 0.5551\n",
            "Epoch 29/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.5287 - loss: 0.5762 - val_accuracy: 0.5688 - val_loss: 0.5536\n",
            "Epoch 30/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.5259 - loss: 0.5707 - val_accuracy: 0.5719 - val_loss: 0.5535\n",
            "Epoch 31/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5320 - loss: 0.5692 - val_accuracy: 0.5656 - val_loss: 0.5543\n",
            "Epoch 32/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.5236 - loss: 0.5678 - val_accuracy: 0.5719 - val_loss: 0.5529\n",
            "Epoch 33/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5723 - loss: 0.5636 - val_accuracy: 0.5688 - val_loss: 0.5542\n",
            "Epoch 34/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5426 - loss: 0.5622 - val_accuracy: 0.5688 - val_loss: 0.5544\n",
            "Epoch 35/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.5283 - loss: 0.5684 - val_accuracy: 0.5688 - val_loss: 0.5535\n",
            "Epoch 36/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5216 - loss: 0.5624 - val_accuracy: 0.5688 - val_loss: 0.5531\n",
            "Epoch 37/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5444 - loss: 0.5704 - val_accuracy: 0.5688 - val_loss: 0.5539\n",
            "Epoch 38/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.5274 - loss: 0.5756 - val_accuracy: 0.5688 - val_loss: 0.5532\n",
            "Epoch 39/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.5114 - loss: 0.5735 - val_accuracy: 0.5688 - val_loss: 0.5530\n",
            "Epoch 40/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5467 - loss: 0.5678 - val_accuracy: 0.5625 - val_loss: 0.5539\n",
            "Epoch 41/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.5378 - loss: 0.5613 - val_accuracy: 0.5688 - val_loss: 0.5540\n",
            "Epoch 42/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5304 - loss: 0.5697 - val_accuracy: 0.5719 - val_loss: 0.5543\n",
            "Epoch 43/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5481 - loss: 0.5681 - val_accuracy: 0.5688 - val_loss: 0.5535\n",
            "Epoch 44/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5190 - loss: 0.5702 - val_accuracy: 0.5688 - val_loss: 0.5540\n",
            "Epoch 45/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5452 - loss: 0.5662 - val_accuracy: 0.5688 - val_loss: 0.5526\n",
            "Epoch 46/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.5086 - loss: 0.5721 - val_accuracy: 0.5688 - val_loss: 0.5528\n",
            "Epoch 47/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.5459 - loss: 0.5755 - val_accuracy: 0.5656 - val_loss: 0.5529\n",
            "Epoch 48/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.5364 - loss: 0.5581 - val_accuracy: 0.5625 - val_loss: 0.5540\n",
            "Epoch 49/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5028 - loss: 0.5685 - val_accuracy: 0.5688 - val_loss: 0.5534\n",
            "Epoch 50/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.5535 - loss: 0.5629 - val_accuracy: 0.5688 - val_loss: 0.5525\n",
            "Epoch 51/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5344 - loss: 0.5680 - val_accuracy: 0.5594 - val_loss: 0.5537\n",
            "Epoch 52/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5172 - loss: 0.5639 - val_accuracy: 0.5625 - val_loss: 0.5529\n",
            "Epoch 53/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.5302 - loss: 0.5683 - val_accuracy: 0.5656 - val_loss: 0.5535\n",
            "Epoch 54/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.5399 - loss: 0.5765 - val_accuracy: 0.5688 - val_loss: 0.5523\n",
            "Epoch 55/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.5399 - loss: 0.5641 - val_accuracy: 0.5719 - val_loss: 0.5533\n",
            "Epoch 56/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5421 - loss: 0.5660 - val_accuracy: 0.5688 - val_loss: 0.5537\n",
            "Epoch 57/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5391 - loss: 0.5647 - val_accuracy: 0.5625 - val_loss: 0.5538\n",
            "Epoch 58/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5110 - loss: 0.5729 - val_accuracy: 0.5688 - val_loss: 0.5537\n",
            "Epoch 59/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.5248 - loss: 0.5624 - val_accuracy: 0.5688 - val_loss: 0.5543\n",
            "Epoch 60/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.5460 - loss: 0.5665 - val_accuracy: 0.5688 - val_loss: 0.5521\n",
            "Epoch 61/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5509 - loss: 0.5726 - val_accuracy: 0.5688 - val_loss: 0.5528\n",
            "Epoch 62/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.5220 - loss: 0.5497 - val_accuracy: 0.5625 - val_loss: 0.5568\n",
            "Epoch 63/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.5504 - loss: 0.5571 - val_accuracy: 0.5688 - val_loss: 0.5535\n",
            "Epoch 64/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.5403 - loss: 0.5608 - val_accuracy: 0.5719 - val_loss: 0.5534\n",
            "Epoch 65/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.5431 - loss: 0.5586 - val_accuracy: 0.5719 - val_loss: 0.5534\n",
            "Epoch 66/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.5331 - loss: 0.5616 - val_accuracy: 0.5719 - val_loss: 0.5525\n",
            "Epoch 67/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5280 - loss: 0.5682 - val_accuracy: 0.5719 - val_loss: 0.5529\n",
            "Epoch 68/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.5444 - loss: 0.5631 - val_accuracy: 0.5688 - val_loss: 0.5531\n",
            "Epoch 69/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.5384 - loss: 0.5599 - val_accuracy: 0.5656 - val_loss: 0.5537\n",
            "Epoch 70/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 0.5210 - loss: 0.5596 - val_accuracy: 0.5688 - val_loss: 0.5526\n",
            "Epoch 71/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5235 - loss: 0.5629 - val_accuracy: 0.5656 - val_loss: 0.5549\n",
            "Epoch 72/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5458 - loss: 0.5550 - val_accuracy: 0.5719 - val_loss: 0.5526\n",
            "Epoch 73/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.5212 - loss: 0.5636 - val_accuracy: 0.5688 - val_loss: 0.5527\n",
            "Epoch 74/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.5195 - loss: 0.5653 - val_accuracy: 0.5719 - val_loss: 0.5520\n",
            "Epoch 75/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5330 - loss: 0.5664 - val_accuracy: 0.5719 - val_loss: 0.5524\n",
            "Epoch 76/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.5223 - loss: 0.5586 - val_accuracy: 0.5656 - val_loss: 0.5528\n",
            "Epoch 77/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.5439 - loss: 0.5553 - val_accuracy: 0.5656 - val_loss: 0.5522\n",
            "Epoch 78/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5385 - loss: 0.5563 - val_accuracy: 0.5656 - val_loss: 0.5527\n",
            "Epoch 79/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5495 - loss: 0.5585 - val_accuracy: 0.5625 - val_loss: 0.5538\n",
            "Epoch 80/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.5474 - loss: 0.5522 - val_accuracy: 0.5688 - val_loss: 0.5528\n",
            "Epoch 81/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.5363 - loss: 0.5578 - val_accuracy: 0.5656 - val_loss: 0.5526\n",
            "Epoch 82/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5070 - loss: 0.5557 - val_accuracy: 0.5656 - val_loss: 0.5528\n",
            "Epoch 83/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.5231 - loss: 0.5629 - val_accuracy: 0.5625 - val_loss: 0.5544\n",
            "Epoch 84/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5504 - loss: 0.5504 - val_accuracy: 0.5656 - val_loss: 0.5522\n",
            "Epoch 85/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.5438 - loss: 0.5627 - val_accuracy: 0.5719 - val_loss: 0.5528\n",
            "Epoch 86/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5514 - loss: 0.5520 - val_accuracy: 0.5688 - val_loss: 0.5541\n",
            "Epoch 87/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5292 - loss: 0.5604 - val_accuracy: 0.5656 - val_loss: 0.5529\n",
            "Epoch 88/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5082 - loss: 0.5497 - val_accuracy: 0.5656 - val_loss: 0.5531\n",
            "Epoch 89/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.5234 - loss: 0.5603 - val_accuracy: 0.5688 - val_loss: 0.5527\n",
            "Epoch 90/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5275 - loss: 0.5557 - val_accuracy: 0.5625 - val_loss: 0.5522\n",
            "Epoch 91/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5146 - loss: 0.5511 - val_accuracy: 0.5594 - val_loss: 0.5523\n",
            "Epoch 92/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5082 - loss: 0.5656 - val_accuracy: 0.5625 - val_loss: 0.5544\n",
            "Epoch 93/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5295 - loss: 0.5541 - val_accuracy: 0.5625 - val_loss: 0.5531\n",
            "Epoch 94/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5361 - loss: 0.5561 - val_accuracy: 0.5656 - val_loss: 0.5525\n",
            "Epoch 95/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.5623 - loss: 0.5512 - val_accuracy: 0.5594 - val_loss: 0.5524\n",
            "Epoch 96/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5144 - loss: 0.5593 - val_accuracy: 0.5437 - val_loss: 0.5571\n",
            "Epoch 97/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5391 - loss: 0.5513 - val_accuracy: 0.5656 - val_loss: 0.5535\n",
            "Epoch 98/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.5239 - loss: 0.5581 - val_accuracy: 0.5594 - val_loss: 0.5538\n",
            "Epoch 99/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.5380 - loss: 0.5464 - val_accuracy: 0.5656 - val_loss: 0.5528\n",
            "Epoch 100/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5003 - loss: 0.5483 - val_accuracy: 0.5562 - val_loss: 0.5556\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model is RNN with F1-macro score: 0.2253645571967104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "best_model = tf.keras.models.load_model('best_model.h5')\n",
        "\n",
        "# Evaluate on test data\n",
        "y_pred_test = best_model.predict(X_test)\n",
        "y_pred_test = np.round(y_pred_test)\n",
        "f1_test = f1_score(y_test, y_pred_test, average='macro')\n",
        "print(f\"F1-macro score on test data: {f1_test}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfSBWAVqnH2t",
        "outputId": "52998463-021d-477b-b4ef-707f70a496c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "F1-macro score on test data: 0.2253645571967104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n"
      ],
      "metadata": {
        "id": "3NAdMoIGn9ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "best_model = tf.keras.models.load_model('best_model.h5')\n",
        "\n",
        "# Predict on the test dataset\n",
        "y_pred_test = best_model.predict(X_test)\n",
        "y_pred_test = np.round(y_pred_test)  # Convert probabilities to 0 or 1 for multi-label classification\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred_test, target_names=['Joy', 'Fear', 'Anger', 'Sadness', 'Surprise'])\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f_WZ9oCoJHN",
        "outputId": "037aa471-40b1-40ff-9d95-c11cb2806415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Joy       0.36      0.10      0.15        94\n",
            "        Fear       0.57      0.72      0.64       232\n",
            "       Anger       0.00      0.00      0.00        52\n",
            "     Sadness       0.50      0.12      0.19       126\n",
            "    Surprise       0.31      0.10      0.15       124\n",
            "\n",
            "   micro avg       0.52      0.32      0.40       628\n",
            "   macro avg       0.35      0.21      0.23       628\n",
            "weighted avg       0.43      0.32      0.33       628\n",
            " samples avg       0.42      0.31      0.33       628\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iEUZouH5oLE4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}