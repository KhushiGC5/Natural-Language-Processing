{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import csv  # Import csv for quoting constants\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "import joblib"
      ],
      "metadata": {
        "id": "bgm3haRQL5li"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install imbalanced-learn for SMOTE\n",
        "!pip install imbalanced-learn\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Download NLTK data once at the beginning\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEXXCGt2MAej",
        "outputId": "441e5362-14a7-41d0-82e0-138d8a22a353"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.3)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataset = pd.read_csv('/content/train_split.csv', encoding='ISO-8859-1', engine='python', quoting=csv.QUOTE_ALL)\n",
        "test_dataset = pd.read_csv('/content/test_split.csv', encoding='ISO-8859-1', engine='python', quoting=csv.QUOTE_ALL)\n"
      ],
      "metadata": {
        "id": "Zk9NwLJwMGm8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure 'text' column exists and handle missing values\n",
        "if 'text' not in train_dataset.columns or 'text' not in test_dataset.columns:\n",
        "    print(\"train_dataset columns:\", train_dataset.columns)\n",
        "    print(\"test_dataset columns:\", test_dataset.columns)\n",
        "    raise ValueError(\"The datasets must contain a 'text' column.\")\n",
        "\n",
        "# Drop rows with missing 'text' values\n",
        "train_dataset = train_dataset.dropna(subset=['text'])\n",
        "test_dataset = test_dataset.dropna(subset=['text'])\n",
        "\n",
        "# Initialize NLP tools\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "all_stopwords = stopwords.words('english')\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    review = re.sub('[^a-zA-Z]', ' ', text)\n",
        "    review = review.lower().split()\n",
        "    # Do not remove stopwords to preserve context\n",
        "    review = [lemmatizer.lemmatize(word) for word in review]\n",
        "    return ' '.join(review)\n",
        "\n",
        "# Apply preprocessing on both the train and test datasets\n",
        "train_corpus = train_dataset['text'].apply(preprocess_text)\n",
        "test_corpus = test_dataset['text'].apply(preprocess_text)\n",
        "\n",
        "# Use TfidfVectorizer with n-grams for text representation\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 3))\n",
        "x_train = tfidf.fit_transform(train_corpus).toarray()\n",
        "x_test = tfidf.transform(test_corpus).toarray()\n",
        "\n",
        "# Save the vectorizer for later use\n",
        "pickle.dump(tfidf, open('/content/c1_TFIDF_Sentiment_Model.pkl', 'wb'))\n",
        "\n",
        "# Combine emotion columns into a single label column\n",
        "emotion_columns = ['Joy', 'Fear', 'Anger', 'Sadness', 'Surprise']\n",
        "train_dataset['label'] = train_dataset[emotion_columns].idxmax(axis=1)\n",
        "test_dataset['label'] = test_dataset[emotion_columns].idxmax(axis=1)\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(train_dataset['label'])\n",
        "y_test = le.transform(test_dataset['label'])\n",
        "\n",
        "# Analyze class distribution\n",
        "print(\"Training set class distribution:\")\n",
        "print(train_dataset['label'].value_counts())\n",
        "\n",
        "print(\"\\nTest set class distribution:\")\n",
        "print(test_dataset['label'].value_counts())\n",
        "\n",
        "\n",
        "x_train_resampled, y_train_resampled = x_train, y_train\n",
        "\n",
        "# Verify the new class distribution after resampling\n",
        "from collections import Counter\n",
        "print(\"\\nResampled training set class distribution:\")\n",
        "print(Counter(y_train_resampled))\n",
        "\n",
        "# Dictionary to store classifiers and their names with class_weight='balanced'\n",
        "classifiers = {\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, class_weight='balanced'),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=0, class_weight='balanced'),\n",
        "    \"Support Vector Machine\": SVC(kernel='linear', probability=True, class_weight='balanced')\n",
        "}\n",
        "\n",
        "# Iterate through each classifier, train it, and evaluate performance\n",
        "for name, classifier in classifiers.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    classifier.fit(x_train_resampled, y_train_resampled)\n",
        "\n",
        "    # Save the model for each classifier\n",
        "    joblib.dump(classifier, f\"/content/{name.replace(' ', '_')}_Sentiment_Model.pkl\")\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = classifier.predict(x_test)\n",
        "\n",
        "    # Evaluate performance\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred, target_names=le.classes_)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"Confusion Matrix for {name}:\\n{cm}\")\n",
        "    print(f\"\\nClassification Report for {name}:\\n{report}\")\n",
        "    print(f\"Accuracy for {name}: {accuracy:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo7jWG19hjte",
        "outputId": "e67c7ecb-e0ef-446b-e135-b9064a8a04cf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set class distribution:\n",
            "label\n",
            "Fear        874\n",
            "Joy         513\n",
            "Sadness      89\n",
            "Surprise     69\n",
            "Anger        55\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Test set class distribution:\n",
            "label\n",
            "Fear        222\n",
            "Joy         126\n",
            "Surprise     18\n",
            "Sadness      18\n",
            "Anger        16\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Resampled training set class distribution:\n",
            "Counter({1: 874, 2: 513, 3: 89, 4: 69, 0: 55})\n",
            "\n",
            "Training Naive Bayes...\n",
            "Confusion Matrix for Naive Bayes:\n",
            "[[  1   9   5   1   0]\n",
            " [  1 165  49   3   4]\n",
            " [  1  77  43   4   1]\n",
            " [  0  13   3   2   0]\n",
            " [  0  10   7   1   0]]\n",
            "\n",
            "Classification Report for Naive Bayes:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Anger       0.33      0.06      0.11        16\n",
            "        Fear       0.60      0.74      0.67       222\n",
            "         Joy       0.40      0.34      0.37       126\n",
            "     Sadness       0.18      0.11      0.14        18\n",
            "    Surprise       0.00      0.00      0.00        18\n",
            "\n",
            "    accuracy                           0.53       400\n",
            "   macro avg       0.30      0.25      0.26       400\n",
            "weighted avg       0.48      0.53      0.50       400\n",
            "\n",
            "Accuracy for Naive Bayes: 0.5275\n",
            "\n",
            "Training Logistic Regression...\n",
            "Confusion Matrix for Logistic Regression:\n",
            "[[  1   8   6   1   0]\n",
            " [  2 160  54   2   4]\n",
            " [  1  56  60   7   2]\n",
            " [  2   4   8   4   0]\n",
            " [  0  11   5   1   1]]\n",
            "\n",
            "Classification Report for Logistic Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Anger       0.17      0.06      0.09        16\n",
            "        Fear       0.67      0.72      0.69       222\n",
            "         Joy       0.45      0.48      0.46       126\n",
            "     Sadness       0.27      0.22      0.24        18\n",
            "    Surprise       0.14      0.06      0.08        18\n",
            "\n",
            "    accuracy                           0.56       400\n",
            "   macro avg       0.34      0.31      0.31       400\n",
            "weighted avg       0.54      0.56      0.55       400\n",
            "\n",
            "Accuracy for Logistic Regression: 0.5650\n",
            "\n",
            "Training Random Forest...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix for Random Forest:\n",
            "[[  0  15   1   0   0]\n",
            " [  0 216   5   1   0]\n",
            " [  0 117   9   0   0]\n",
            " [  0  17   1   0   0]\n",
            " [  0  18   0   0   0]]\n",
            "\n",
            "Classification Report for Random Forest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Anger       0.00      0.00      0.00        16\n",
            "        Fear       0.56      0.97      0.71       222\n",
            "         Joy       0.56      0.07      0.13       126\n",
            "     Sadness       0.00      0.00      0.00        18\n",
            "    Surprise       0.00      0.00      0.00        18\n",
            "\n",
            "    accuracy                           0.56       400\n",
            "   macro avg       0.23      0.21      0.17       400\n",
            "weighted avg       0.49      0.56      0.44       400\n",
            "\n",
            "Accuracy for Random Forest: 0.5625\n",
            "\n",
            "Training Support Vector Machine...\n",
            "Confusion Matrix for Support Vector Machine:\n",
            "[[  0  10   5   1   0]\n",
            " [  1 153  66   2   0]\n",
            " [  0  53  72   1   0]\n",
            " [  1   8   8   1   0]\n",
            " [  0  11   7   0   0]]\n",
            "\n",
            "Classification Report for Support Vector Machine:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Anger       0.00      0.00      0.00        16\n",
            "        Fear       0.65      0.69      0.67       222\n",
            "         Joy       0.46      0.57      0.51       126\n",
            "     Sadness       0.20      0.06      0.09        18\n",
            "    Surprise       0.00      0.00      0.00        18\n",
            "\n",
            "    accuracy                           0.56       400\n",
            "   macro avg       0.26      0.26      0.25       400\n",
            "weighted avg       0.51      0.56      0.54       400\n",
            "\n",
            "Accuracy for Support Vector Machine: 0.5650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}